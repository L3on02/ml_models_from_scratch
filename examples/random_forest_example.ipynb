{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest\n",
    "\n",
    "As with the Decision Tree example, we will again compare the performance of our own implementation to the one from the sklearn library. To avoid redundancy, in this notebook we will only focus on the examples where the single Decision Tree struggled and skip over the simple datasets where it performed well. The datasets we will focus on will be the digits dataset for classification, aswell as the diabetes dataset for regression.\n",
    "Finally we will also use the large diamond dataset to compare the relative performance of the two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from models.random_forest import RandomForestClassifier as OwnRandomForestClassifier, RandomForestRegressor as OwnRandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as SklearnRandomForestClassifier, RandomForestRegressor as SklearnRandomForestRegressor\n",
    "\n",
    "from utils.reports import evaluate_classification, evaluate_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_diabetes\n",
    "from datasets.diamonds import load_diamonds\n",
    "\n",
    "ds_c_hard = load_digits()\n",
    "X, Y = ds_c_hard.data, ds_c_hard.target\n",
    "X_c_hard_train, X_c_hard_test, Y_c_hard_train, Y_c_hard_test = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_medium = load_diabetes()\n",
    "X, Y = ds_r_medium.data, ds_r_medium.target\n",
    "X_r_medium_train, X_r_medium_test, Y_r_medium_train, Y_r_medium_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_hard = load_diamonds()\n",
    "X, Y = ds_r_hard.data, ds_r_hard.target\n",
    "X_r_hard_train, X_r_hard_test, Y_r_hard_train, Y_r_hard_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the hard classification example, we can immediately see that the Random Forrest is able to achieve a much higher accuracy than the individual Decision Tree, due to its ability to grasp more complex data, as is present in the digits dataset (the Decision Trees achieved an accuracy of around 0.85). To avoid excessive compute durations when running the notebook, we do not perform a grid search for hyperparameters and instead rely on the default values. Just note that the potential results could be improved with a more thorough search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.96, Recall: 0.96, F1-Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = OwnRandomForestClassifier()\n",
    "\n",
    "rf_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = rf_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.97, Recall: 0.97, F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = SklearnRandomForestClassifier()\n",
    "\n",
    "rf_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = rf_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diabetes set we can only observe marginal improvements over standart desicion trees. Given that the sklean implementation performs equally poor, we can assume that the dataset is simply not well suited for this type of model and that there are no inherent flaws in our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 44.63, MSE: 2928.43, R²: 0.45\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = OwnRandomForestRegressor()\n",
    "\n",
    "rf_regressor.fit(X_r_medium_train, Y_r_medium_train)\n",
    "Y_r_medium_pred = rf_regressor.predict(X_r_medium_test)\n",
    "\n",
    "evaluate_regression(Y_r_medium_test, Y_r_medium_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 45.00, MSE: 3051.44, R²: 0.42\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = SklearnRandomForestRegressor()\n",
    "\n",
    "rf_regressor.fit(X_r_medium_train, Y_r_medium_train)\n",
    "Y_r_medium_pred = rf_regressor.predict(X_r_medium_test)\n",
    "\n",
    "evaluate_regression(Y_r_medium_test, Y_r_medium_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the diamonds dataset shows that our implementation is efficient enough, to be able to handle large datasets. In terms of performance, it is not surprising that we achieve a high accuracy, as this has already been achieved by individual decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 294.72, MSE: 332031.56, R²: 0.98\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = OwnRandomForestRegressor()\n",
    "\n",
    "rf_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = rf_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 266.15, MSE: 290207.92, R²: 0.98\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = SklearnRandomForestRegressor()\n",
    "\n",
    "rf_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = rf_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
