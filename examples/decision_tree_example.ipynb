{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "In this example, we will take a look at the Decision Tree and test it's performance on several datasets while comparing it to the performance of scikit-learn's Decision Tree on the same datasets. The datasets used for testing are 5 in total, 3 for classification and 2 for regression with increasing complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the necessary datasets and split them into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from models.decision_tree import DecisionTreeClassifier as OwnDecisionTreeClassifier, DecisionTreeRegressor as OwnDecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier, DecisionTreeRegressor as SklearnDecisionTreeRegressor\n",
    "\n",
    "from utils.reports import evaluate_classification, evaluate_regression\n",
    "from utils.grid_search_cv import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "\n",
    "# set up a list of hyperparameters to search over for all trees\n",
    "params = {\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11],\n",
    "    'min_samples_split': [2, 3, 5, 7],\n",
    "    'min_samples_leaf': [1, 3, 5, 7]\n",
    "}\n",
    "param_grid = list(ParameterGrid(params))\n",
    "\n",
    "# Load datasets\n",
    "# one easy, one medium, one hard for each classification and regression\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn.datasets import load_diabetes, fetch_california_housing\n",
    "\n",
    "# diamonds dataset is a very large regression dataset which will test the efficiency of the algorithms\n",
    "from datasets.diamonds import load_diamonds\n",
    "\n",
    "\n",
    "ds_c_easy = load_iris()\n",
    "X, Y = ds_c_easy.data, ds_c_easy.target\n",
    "X_c_easy_train, X_c_easy_test, Y_c_easy_train, Y_c_easy_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_c_medium = load_breast_cancer()\n",
    "X, Y = ds_c_medium.data, ds_c_medium.target \n",
    "X_c_medium_train, X_c_medium_test, Y_c_medium_train, Y_c_medium_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_c_hard = load_digits()\n",
    "X, Y = ds_c_hard.data, ds_c_hard.target\n",
    "X_c_hard_train, X_c_hard_test, Y_c_hard_train, Y_c_hard_test = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_easy = fetch_california_housing()\n",
    "X, Y = ds_r_easy.data, ds_r_easy.target\n",
    "X_r_easy_train, X_r_easy_test, Y_r_easy_train, Y_r_easy_test = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_medium = load_diabetes()\n",
    "X, Y = ds_r_medium.data, ds_r_medium.target\n",
    "X_r_medium_train, X_r_medium_test, Y_r_medium_train, Y_r_medium_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_hard = load_diamonds()\n",
    "X, Y = ds_r_hard.data, ds_r_hard.target\n",
    "X_r_hard_train, X_r_hard_test, Y_r_hard_train, Y_r_hard_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "First we will look at our own implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "dt_classifier.fit(X_c_easy_train, Y_c_easy_train)\n",
    "Y_c_easy_pred = dt_classifier.predict(X_c_easy_test)\n",
    "\n",
    "evaluate_classification(Y_c_easy_test, Y_c_easy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model achieves a perfect accuracy on the Iris dataset (This is to be expected as the dataset is very simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier(max_depth=5)\n",
    "dt_classifier.fit(X_c_easy_train, Y_c_easy_train)\n",
    "Y_c_easy_pred = dt_classifier.predict(X_c_easy_test)\n",
    "\n",
    "evaluate_classification(Y_c_easy_test, Y_c_easy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without much surprise, scikit-learn's Decision Tree also achieves a perfect accuracy here. Moving on the Breast Cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.96, Recall: 1.00, F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_medium_train, Y_c_medium_train)\n",
    "Y_c_medium_pred = dt_classifier.predict(X_c_medium_test)\n",
    "\n",
    "evaluate_classification(Y_c_medium_test, Y_c_medium_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.96, Recall: 0.96, F1-Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_medium_train, Y_c_medium_train)\n",
    "Y_c_medium_pred = dt_classifier.predict(X_c_medium_test)\n",
    "\n",
    "evaluate_classification(Y_c_medium_test, Y_c_medium_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, while not completely perfect, both models still achieve a very high, similar accuracy of 96% with our model even slightly edgeing out scikits implementation in terms of recall. Finally, the digits dataset. This is particularly tricky since we are now dealing with non-binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.88, Recall: 0.87, F1-Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = dt_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.86, Recall: 0.85, F1-Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = dt_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately can see, that both models take a considerable hit in accuracy. Given the complexity of the dataset, this is to be expected. However, the de-facto standard implementation of a decision tree by sklearn only outperforms our own implementation by a single percentage point. This indicates that the issue doesn't lie in our implementation, but rather that we are reaching the limits of what single a decision tree can achieve on this dataset. After taking a look at the regression datasets, we  will see how our ensamble methods can help us improve on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.41, MSE: 0.38, R²: 0.71\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 11, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
    "dt_regressor = OwnDecisionTreeRegressor(max_depth=11, min_samples_leaf=7, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_easy_train, Y_r_easy_train)\n",
    "Y_r_easy_pred = dt_regressor.predict(X_r_easy_test)\n",
    "\n",
    "evaluate_regression(Y_r_easy_test, Y_r_easy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.41, MSE: 0.37, R²: 0.72\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 11, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
    "dt_regressor = SklearnDecisionTreeRegressor(max_depth=11, min_samples_leaf=7, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_easy_train, Y_r_easy_train)\n",
    "Y_r_easy_pred = dt_regressor.predict(X_r_easy_test)\n",
    "\n",
    "evaluate_regression(Y_r_easy_test, Y_r_easy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 45.20, MSE: 3257.41, R²: 0.39\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
    "dt_regressor = OwnDecisionTreeRegressor(max_depth=5, min_samples_leaf=7, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_medium_train, Y_r_medium_train)\n",
    "Y_r_medium_pred = dt_regressor.predict(X_r_medium_test)\n",
    "\n",
    "evaluate_regression(Y_r_medium_test, Y_r_medium_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 41.86, MSE: 2810.52, R²: 0.47\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
    "dt_regressor = SklearnDecisionTreeRegressor(max_depth=5, min_samples_leaf=7, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_medium_train, Y_r_medium_train)\n",
    "Y_r_medium_pred = dt_regressor.predict(X_r_medium_test)\n",
    "\n",
    "evaluate_regression(Y_r_medium_test, Y_r_medium_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 321.93, MSE: 364038.26, R²: 0.98\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 11, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
    "dt_regressor = OwnDecisionTreeRegressor(max_depth=11, min_samples_leaf=5, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = dt_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 320.34, MSE: 378656.13, R²: 0.98\n"
     ]
    }
   ],
   "source": [
    "# GridSearch optimal params: {'max_depth': 11, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
    "dt_regressor = SklearnDecisionTreeRegressor(max_depth=11, min_samples_leaf=5, min_samples_split=2)\n",
    "\n",
    "dt_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = dt_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
