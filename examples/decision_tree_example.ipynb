{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "In this example, we will take a look at the Decision Tree and test it's performance on several datasets while comparing it to the performance of scikit-learn's Decision Tree on the same datasets. The datasets used for testing are 5 in total, 3 for classification and 2 for regression with increasing complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from models.decision_tree import DecisionTreeClassifier as OwnDecisionTreeClassifier, DecisionTreeRegressor as OwnDecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier, DecisionTreeRegressor as SklearnDecisionTreeRegressor\n",
    "\n",
    "from utils.reports import evaluate_classification, evaluate_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the necessary datasets and split them into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "# one easy, one medium, one hard for each classification and regression\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn.datasets import load_diabetes, fetch_california_housing\n",
    "\n",
    "# diamonds dataset is a very large regression dataset which will test the efficiency of the algorithms\n",
    "from datasets.diamonds import load_diamonds\n",
    "\n",
    "\n",
    "ds_c_easy = load_iris()\n",
    "X, Y = ds_c_easy.data, ds_c_easy.target\n",
    "X_c_easy_train, X_c_easy_test, Y_c_easy_train, Y_c_easy_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_c_medium = load_breast_cancer()\n",
    "X, Y = ds_c_medium.data, ds_c_medium.target \n",
    "X_c_medium_train, X_c_medium_test, Y_c_medium_train, Y_c_medium_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_c_hard = load_digits()\n",
    "X, Y = ds_c_hard.data, ds_c_hard.target\n",
    "X_c_hard_train, X_c_hard_test, Y_c_hard_train, Y_c_hard_test = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_easy = fetch_california_housing()\n",
    "X, Y = ds_r_easy.data, ds_r_easy.target\n",
    "X_r_easy_train, X_r_easy_test, Y_r_easy_train, Y_r_easy_test = train_test_split(X , Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_medium = load_diabetes()\n",
    "X, Y = ds_r_medium.data, ds_r_medium.target\n",
    "X_r_medium_train, X_r_medium_test, Y_r_medium_train, Y_r_medium_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "ds_r_hard = load_diamonds()\n",
    "X, Y = ds_r_hard.data, ds_r_hard.target\n",
    "X_r_hard_train, X_r_hard_test, Y_r_hard_train, Y_r_hard_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will look at our own implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "dt_classifier.fit(X_c_easy_train, Y_c_easy_train)\n",
    "Y_c_easy_pred = dt_classifier.predict(X_c_easy_test)\n",
    "\n",
    "evaluate_classification(Y_c_easy_test, Y_c_easy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model achieves a perfect accuracy on the Iris dataset (This is to be expected as the dataset is very simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier(max_depth=5)\n",
    "dt_classifier.fit(X_c_easy_train, Y_c_easy_train)\n",
    "Y_c_easy_pred = dt_classifier.predict(X_c_easy_test)\n",
    "\n",
    "evaluate_classification(Y_c_easy_test, Y_c_easy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without much surprise, scikit-learn's Decision Tree also achieves a perfect accuracy here. Moving on the Breast Cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.96, Recall: 1.00, F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_medium_train, Y_c_medium_train)\n",
    "Y_c_medium_pred = dt_classifier.predict(X_c_medium_test)\n",
    "\n",
    "evaluate_classification(Y_c_medium_test, Y_c_medium_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.94, Recall: 0.96, F1-Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_medium_train, Y_c_medium_train)\n",
    "Y_c_medium_pred = dt_classifier.predict(X_c_medium_test)\n",
    "\n",
    "evaluate_classification(Y_c_medium_test, Y_c_medium_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, while not completely perfect, both models still achieve a very high, similar accuracy of 96% with our model even slightly edgeing out scikits implementation in terms of recall. Finally, the digits dataset. This is particularly tricky since we are now dealing with non-binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.88, Recall: 0.87, F1-Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OwnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = dt_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.86, Recall: 0.85, F1-Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = SklearnDecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(X_c_hard_train, Y_c_hard_train)\n",
    "Y_c_hard_pred = dt_classifier.predict(X_c_hard_test)\n",
    "\n",
    "evaluate_classification(Y_c_hard_test, Y_c_hard_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately can see, that both models take a considerable hit in accuracy. Given the complexity of the dataset, this is to be expected. However, the de-facto standard implementation of a decision tree by sklearn only outperforms our own implementation by a single percentage point. This indicates that the issue doesn't lie in our implementation, but rather that we are reaching the limits of what single a decision tree can achieve on this dataset. Let's see how our ensamble methods can improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "Precision: 0.87, Recall: 0.87, F1-Score: 0.87\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 309.19, MSE: 369984.86, R²: 0.98\n"
     ]
    }
   ],
   "source": [
    "dt_regressor = OwnDecisionTreeRegressor()\n",
    "\n",
    "dt_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = dt_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 352.51, MSE: 537955.89, R²: 0.97\n"
     ]
    }
   ],
   "source": [
    "dt_regressor = SklearnDecisionTreeRegressor()\n",
    "\n",
    "dt_regressor.fit(X_r_hard_train, Y_r_hard_train)\n",
    "Y_r_hard_pred = dt_regressor.predict(X_r_hard_test)\n",
    "\n",
    "evaluate_regression(Y_r_hard_test, Y_r_hard_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
